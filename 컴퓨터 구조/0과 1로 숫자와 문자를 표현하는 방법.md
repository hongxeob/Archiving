> 컴퓨터는 0과 1로 모든 정보를 표현하고, 0과1로 표현된 정보만을 이해 할수 있다! 그런데..?

![](https://velog.velcdn.com/images/hongxeob/post/1e1c6099-02ee-489b-9f5f-b6ada7957f3a/image.png)

우리는 컴퓨터가 표현하는 **정보 단위**를 알 필요가 있다.  
그리고 0과 1만으로 숫자를 표현하는 방법 또한 알아야 한다!

### 컴퓨터가 이해하는 정보 단위

-   비트 (bit): 0과 1을 표현하는 가장 작은 정보 단위(ex-꺼짐or켜짐)
-   바이트 : 여덟개의 비트를 묶은 단위
-   단위가 커지면 킬로바이트(kB),메가바이트(MB),기가바이트(GB),테라바이트(TB)등도 있다
-   워드
    -   CPU가 한 번에 처리할 수 있는 정보의 크기 단위
    -   하프 워드, 풀 워드, 더블 워드 등이 있다

### 이진법

-   0과 1로 수를 표현 하는 방법
-   숫자가 1을 넘어가는 시점에 자리 올림
-   우리가 일상적으로 사용하는 9를 넘어설때 자리올림을 하는 진법은 10진법

### 이진법의 음수 표현 방법

-   2의 보수
-   모든 0과 1을 뒤집고 1 더한 값

### 십육진법

-   십진수가 0,1,2,3,------10,11,12,13,14,15,16,17 이면
-   십육진수는 0,1,2,3,----8,9,A,B,C,----E,F,10(자리올림),11,----

---

> 지금까지가 0과 1로 다양한 숫자를 표현하는 방법이었다면  
> 이번엔 다양한 문자들은 어떻게 표현 할까?

## 0과 1로 문자를 표현하는 방법

### 문자 집합과 인코딩

-   문자 집합(character set)
    -   컴퓨터가 이해할 수 있는 문자의 모음
-   인코딩(encoding)
    -   코드화하는 과정
    -   문자를 0과 1로 이루어진 문자 코드로 변환하는 과정
-   디코딩(decoding)
    -   인코딩의 반대 과정
    -   코드를 해석하는 과정
    -   0과 1로 표현된 문자 코드로 문자로 변환하는 과정

### 아스키 코드

-   초창기 문자 집합 중 하나
-   알파벳(대소문자 포함),아라비아 숫자,일부 특수 문자 및 제어 문자
-   7비트로 하나의 문자 표현
    -   8비트 중 1비트는 오류 검출을 위해 사용되는 패리티 비트(parity bit)
-   간단한 인코딩이지만 한글을 포함한 다른 언어 문자, 다양한 특수문자 표현이 불가 하다

### 한글 인코딩

-   완성형 인코딩
    -   완성된 단어 하나 하나에 코드를 부여해서 합치는 방법(홍+길+동)
-   조합형 인코딩
    -   초정,중성,종성등 각각의 모음 자음에 일일이 코드를 부여해서 하는 법(ㅎ+ㅗ+ㅇ+ㄱ+ㅣ+ㄹ----)

### EUC-KR

-   2300여개의 한글 표현 가능
-   여전히 모든 한글을 표현하기에는 부족하다
-   뷁,샒 과 같은 한글은 표현이 불가

**이렇게 하면 다국어 프로그램을 만들면 모든 언어의 인코딩 방식을 이해 해야한다..OMG**

> 모든 언어, 특수문자까지 통일된 문자 집합을 사용하면 어떨까?  
> 그런 모든 것을 인코딩 해주는 방식이 있다면?!

## 유니코드 문자 집합과 utf-8

### 유니코드

-   한글,영어,화살표,이모티콘등 모두 통일된 문자 집합유니코드의 인코딩 방식
-   utf-8,utf-16,utf-32 ----...등이 있다

### utf-8 인코딩

-   UTF(Unicode Transformation Format) == 유니코드 인코딩 방법
-   가변 길이 인코딩 : 인코딩의 결과가 1바이트~ 4바이트
-   인코딩 결과가 몇 바이트가 될지는 유니코드에 부여된 값에 따라 다르다
