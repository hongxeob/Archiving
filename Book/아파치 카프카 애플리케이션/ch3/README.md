# 3. 카프카 기본 개념 설명

## 3.1 카프카 브로커, 클로스터 주키퍼

## 카프카 브로커

- 하나의 서버에는 한 개의 카프카 브로커가 실행된다.
- **3대 이상을 묶어서 클러스터**로 운영한다.
- 데이터를 전달받아 토픽의 파티션에 데이터를 저장하고, 전달한다.
- 데이터는 **파일 시스템**에 저장된다.

> 카프카는 데이터를 메모리나 데이터베이스가 아니라 파일에 저장하는데, `파일 시스템에 저장하면 파일 입출력으로 인해 느리지 않을까?`
> - 카프카는 페이지 캐시(page cache)를 사용해 디스크 입출력 속도를 높였다.
> - 한 번 읽은 파일의 내용은 메모리의 페이지 캐시 영역에 저장된다.
> - JVM 상에서 동작하는 카프카가 직접 캐시를 구현하는 게 아니다. (그랬더라면 gc가 자주 일어났을 것이다.)
    >
- 그래서 카프카 힙 사이즈를 크게 설정하지 않아도 된다.

### 데이터 복제, 싱크

장애 발생시에도 데이터를 유실하지 않고 안전하게 사용하기 위해서 데이터 복제(싱크)를 진행한다.<br>
카프카의 데이터 복제는 **파티션 단위**로 이루어지며 복제된 파티션은 `리더` & `팔로워`로 구성된다.<br>

- 팔로워의 파티션은 리더 파티션으로부터 데이터를 가져와서 자신의 파티션에 저장한다.
- 복제 개수만큼 저장 용량이 증가한다는 단점을 가지고 있다.
- 리더 파티션에 장애가 발생하면 다른 팔로워 파티션이 그 기능을 위임 받는다.

### 컨트롤러

클러스터의 다수 브로커 중 한 대가 컨트롤러의 역할을 한다.<br>

- 컨트롤러는 다른 브로커들의 상태를 체크한다.
- 브로커가 클러스터에서 빠지는 경우 해당 브로커에 존재하는 **리더 파티션을 재분배한다**.

### 데이터 삭제

카프카는 다른 메시징 플랫폼과 다르게 컨슈머가 데이터를 가져가더라도 토픽의 데이터는 삭제되지 않는다.<br>
컨슈머나 프로듀서가 데이터 삭제를 요청할 수도 없다. **오직 브로커만이 데이터를 삭제할 수 있다.**

- 데이터 삭제는 파일 단위로 이루어지는데 이 단위를 `로그 세그먼트`라고 부른다.
    - 이 세그먼트에는 다수의 데이터가 들어있기 때문에 일반적인 데이터베이스처럼 특정 데이터를 선별해서 삭제할 수 없다.
- 닫힌 세그먼트 파일은 `log.retention.bytes` 또는 `log.retention.ms` 옵션에 설정값이 넘으면 삭제된다.
- 카프카는 데이터를 삭제하지 않고 메세지 키를 기준으로 오래된 데이터를 압축하는 정책(토픽 압축 정책)을 가져갈 수 있다.

### 코디네이터

코디네이터는 컨슈머 그룹의 상태를 체크하고 파티션을 컨슈머와 매칭되도록 분배하는 역할을 한다.

- 브로커 중 하나가 코디네이터 역할을 수행한다.
- 파티션을 컨슈머로 재할당하는 과정을 수행한다.
    - 즉 **리밸런스**를 수행한다.

### 주키퍼란?

여기까지는 브로커에 대해 알아보았다. 그러면 주키퍼(zookeeper)는 뭘까?

- 카프카의 메타데이터를 관리한다. (브로커 정보(어느 보안 규칙으로 통신하는지, jmx port 상태 정보, host 정보 등), 컨트롤러 정보, 토픽 정보 등)
- 카프카 서버에서 직접 주키퍼에 붙으려면 카프카 서버에서 실행되고 있는 주키퍼에 연결해야 한다.

---

## 3.2 토픽과 파티션

### 토픽

- 데이터를 구분하기 위해 사용하는 단위
- 토픽은 **1개 이상의 파티션을 소유**한다.
- 파티션에는 프로듀서가 보낸 데이터들이 들어가 저장되는데, 이 데이터를 `레코드(record)`라고 부른다.
- 토픽의 레코드는 다양한 목적을 가진 여러 컨슈머 그룹들이 데이터를 여러 번 가져갈 수 있다.

### 파티션

- 카프카의 병렬 처리의 핵심으로 그룹으로 묶인 컨슈머들이 레코드(=데이터)를 병렬로 처리할 수 있게 매칭된다.
    - 파티션은 큐형태로 FIFO(First In First Out) 구조이나, 큐와 다르게 pop 되었다고 데이터가 삭제되지 않는다.
- 컨슈머의 처리량이 한정된 상황에서 많은 레코드를 병렬로 처리하기 위한 가장 좋은 방법은 컨슈머의 개수를 늘리는 것이다.
    - 컨슈머 개수를 늘리면서 동시에 파티션 개수도 늘리면 처리량을 증가시킬 수 있다.

#### 토픽이름 제약조건

> 토픽 이름을 생성할때 제약조건이 있다.

- 빈 문자열 지원 X
- 토픽이름은 마침표 하나 또는 둘로 생성될 수 없다.
- 토픽 이름의 길이는 249자 미만이어야 한다.
- 토픽 이름은 영어 대소문자, 숫자, 마침표(.), 언더바(_), 하이픈(-) 조합으로 생성할 수 있다.
- 카프카 내부 로직 관리 목적으로 사용되는 토픽(__consumer_offsets,__transaction_state)은 생성 불가능하다.
- 내부적으로 사용하는 로직 때문에 토픽 이름에 마침표와 언더바가 동시에 들어가면안된다.
    - 생성은 가능하나, 이슈가 발생할 수 있기 때문에 WARNING표시

#### 의미있는 토픽 이름을 짓는다.

예시)

- <환경>.<팀명>.<애플리케이션명>.<메시지타입>
    - `prod.marketing.sms-platform.json`
- <프로젝트명>.<서비스명>.<환경>.<이벤트명>
    - `commerece.payment.prod.notification`
- <환경>.<서비스명>.<JIRA번호>.<메시지타입>
    - `dev.email-sender.jira-1234.email-vo-custom`
- <카프카클러스터명>.<환경>.<서비스명>.<메시지타입>
    - `aws-kafka.live.marketing-platform.json`
- **토픽 이름은 변경할 수 없다. 삭제 후 다시 생성해야 한다.**

### 레코드

> 레코드 : `오프셋`, `타임스탬프`+`메세지 키`+`메세지 값`,`헤더`로 구성된다.<br>
> 프로듀서가 생성한 레코드가 브로커에 전송되면 오프셋과 타임스탬프가 지정되어 저장된다. <br>
> 브로커에 한 번 적재된 레코드는 수정할 수 없고, 로그 리텐션 기간 또는 용량에 따라서만 삭제된다.

- `메세지 키` : 메세지 값을 순서대로 처리하거나 종류를 나타내는 값으로 해당 키 값의 해시값을 토대로 파티션을 지정한다.
    - 동일 메세지 키라면 동일 파티션으로 들어간다.
    - 다만 어느 파티션에 지정될 지 알 수 없고 파티션 개수가 변하면 메세지 키와 파티션 매칭이 달라지게 되므로 주의해야 한다.
    - 메세지 키를 설정하지 않으면 null로 설정되고, 메세지 키가 null인 레코드는 기본 설정 파티셔너에 따라 파티션에 분배된다.
    - **파티션 개수 변경 시 재분배됨으로 운영 중에 값을 변경해서는 안됨**
- `메세지 값` :  실제 처리할 데이터
    - 메세지 키와 메세지 값은 직렬화되어 브로커로 전송된다.
    - 컨슈머는 직렬화와 동일한 형태로 역직렬화를 수행해야 한다. (프로듀서가 String으로 직렬화 한것을 컨슈머가 Integer로 역직렬화하면 에러가 발생한다.)
- `오프셋` : 컨슈머가 데이터를 가져갔음을 나타내는 위치값
- `타임스탬프` : 프로듀서에서 해당 레코드가 생성된 시점 또는 브로커에 적재된 시점을 의미함
- `헤더` : 레코드의 추가적인 정보를 담는 메타데이터 저장소 용도
