# 1.1 카프카의 탄생
- 링크드인에서 서비스의 성장과 더불어 내부 아키텍처가 거대해지고 운영 애플리케이션의 수가 증가했다.
- 이에 따라 다음과 같은 문제가 생겼다.
  - 데이터를 전송하는 라인이 기하급수적으로 복잡해지기 시작했다.
  - 소스코드 및 버전 관리에서 이슈가 발생했다.
  - 타겟 애플리케이션에 장애가 발생하면 소스 애플리케이션으로 장애가 전파되는 문제가 발생했다.

위의 문제점들을 해결하기 위해 등장한 것이 `kafka` 이다.<br>
카프카를 데이터 전송 파이프라인으로 도입하게 되어 복잡한 데이터 의존성 관계를 카프카와 애플리케이션들과의 관계를 단순화되었고 애플리케이션 입장에서 데이터 전송의 타켓이 카프카로 통일되었기 때문에 데이터 전송과 관련된 의존성 설정 문제에서 자유로워질 수 있었다.<br>
아키텍처 역시 단순화된 데이터 전송 라인으로 명확해졌다.

# 1.2 카프카의 특징

### 높은 처리량
> 많은 양의 데이터를 `묶음단위`로 처리함으로써 데이터 전송에 필요한 리소스를 줄여 높은 처리량을 가지도록 동작한다.

### 확장성
> 처리되는 데이터의 양에 따라 브로커의 개수를 `Scale-In/Out`함으로써 유동적인 데이터 처리가 가능하다. 

### 영속성
> 메모리 영역에 데이터를 저장하는 것이아닌 디스크 영역에 데이터를 저장/전송함으로써 데이터 유실을 방지할 수 있다. <br>
> 디스크 영역의 데이터 저장시 성능 저하는 운영체제 레벨의 파일 시스템 (페이지 캐시 메모리 영억)을 최대한 활용하여 성능을 향상시킨다.

### 고가용성
> 3대 이상의 서버들로 운영되는 카프카 클러스터를 사용하여 데이터 복제를 통해서 고가용성을 제공한다.

**why 3대 이상의 서버를 사용하는가?**
- 2대의 서버로 운영시 1대의 서버가 다운되면 데이터 복제가 불가능하다.
  - 브로커 간에 데이터가 복제되는 시간 차이로 인해 일부 데이터가 유실될 가능성이 있다.
- 3대의 서버로 운영시 1대의 서버가 다운되어도 데이터 복제가 가능하다.
- 유실을 막기 위해서 `min.insync.replicas` 옵션을 2대 이상으로 설정하며 완전한 복제를 보장한다.
